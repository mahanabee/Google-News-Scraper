# Google News Scraper

[![Promo](https://github.com/bright-jp/Google-News-Scraper/blob/main/Proxies%20and%20scrapers%20GitHub%20bonus%20banner.png)](https://brightdata.jp/products/serp-api/google-search/news?promo=github15) 

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã§ã¯ã€Google News ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã™ã‚‹ãŸã‚ã® 2 ã¤ã®æ–¹æ³•ã‚’æä¾›ã—ã¾ã™ã€‚
- **ç„¡æ–™ã®æ–¹æ³•:** å°è¦æ¨¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚„å­¦ç¿’ã«æœ€é©ã§ã™
- **Google News API:** å¤§è¦æ¨¡ã§ä¿¡é ¼æ€§ãŒé«˜ãã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã«æœ€é©ã§ã™

## Table of Contents

- [Method 1: Free Google News Scraper](#method-1-free-google-news-scraper)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
  - [Usage](#usage)
  - [Output](#output)
- [Common Scraping Challenges](#common-scraping-challenges)
- [Method 2: Bright Data Google News API](#method-2-bright-data-google-news-api)
  - [Key Benefits](#key-benefits)
  - [Getting Started with the Google News API](#getting-started-with-the-google-news-api)
  - [Key Input Parameters](#key-input-parameters)
  - [Sample Result](#sample-result)
  - [Ready-to-Use Python Code](#ready-to-use-python-code)
  - [Understanding the API Implementation](#understanding-the-api-implementation)
  - [Customizing Your Data Collection](#customizing-your-data-collection)

## Method 1: Free Google News Scraper
<img width="700" alt="image" src="https://github.com/user-attachments/assets/a7d34ffe-17c6-4c59-acbf-aaf84ed1b13e">

ã“ã®ç„¡æ–™ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€èˆˆå‘³ã®ã‚ã‚‹ä»»æ„ã®ãƒˆãƒ”ãƒƒã‚¯ã«åŸºã¥ã„ã¦ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’åé›†ã§ãã¾ã™ã€‚è¦‹å‡ºã—ã‹ã‚‰å…¬é–‹æ—¥ã¾ã§ã€ã™ã¹ã¦ãŒãã‚Œã„ã«æ•´ç†ã•ã‚ŒãŸå½¢ã§å–å¾—ã§ãã¾ã™ã€‚

### Prerequisites
- Python 3.9+
- ä¸»è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ 2 ã¤:
  - [aiohttp](https://pypi.org/project/aiohttp/)ï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ç”¨ï¼‰
  - [beautifulsoup4](https://pypi.org/project/beautifulsoup4/)ï¼ˆHTML è§£æç”¨ï¼‰

### Installation
1. ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¾ã™:

    ```bash
    git clone https://github.com/bright-jp/Google-News-Scraper.git
    ```
3. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•ã—ã¾ã™:

    ```bash
    cd Google-News-Scraper
    ```
4. å¿…è¦ãªä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™:

    ```bash
    pip install -r requirements.txt
    ```
### Usage
1. `free_scraper` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•ã—ã€`main.py` ã‚’é–‹ãã¾ã™
2. ãƒ•ã‚¡ã‚¤ãƒ«å†…ã§æ¤œç´¢èªã‚’å®šç¾©ã—ã¾ã™:

    ```bash
    search_terms = [
        "artificial intelligence",
        "climate change",
        "space exploration",
        # Add more search terms as needed
    ]
    ```
3. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’å®Ÿè¡Œã—ã¾ã™:

    ```bash
    python main.py
    ```
### Output
ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã¯ JSON ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™:
- æ¤œç´¢èªã”ã¨ã®å€‹åˆ¥ JSON ãƒ•ã‚¡ã‚¤ãƒ«
- ã™ã¹ã¦ã®æ¤œç´¢èªã®ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ `combined_results.json` ãƒ•ã‚¡ã‚¤ãƒ«

JSON å‡ºåŠ›å†…ã®å„è¨˜äº‹ã«ã¯æ¬¡ãŒå«ã¾ã‚Œã¾ã™:
```json
{
    "title": "OpenAI launches full o1 model with image uploads and analysis, debuts ChatGPT Pro - VentureBeat",
    "link": "https://news.google.com/rss/articles/CBMipgFBVV95cUxQTTVmS1I4aW1QanZXTnBfa2tBR3d0Y2JzNjJJNldBZTd1TVVfRmpxaUM3bGJld3RycXhPbU8wM1loT0JGd2JDRzFmU1pLU3FSbkRRZ0FPY29INmdhU1RsWXFqXzdLTjNCbU5ES3pIQXZLbTVmMWVhc0FqVlljeWNPOHZMeFlXV2F5Q21ac0lSZVhIOHlnS05sdkR5ZjhJTU9HazJ6MWJR?oc=5",
    "publication_date": "Thu, 05 Dec 2024 18:00:00 GMT",
    "source": "VentureBeat",
    "source_url": "https://venturebeat.com",
    "guid": "CBMipgFBVV95cUxQTTVmS1I4aW1QanZXTnBfa2tBR3d0Y2JzNjJJNldBZTd1TVVfRmpxaUM3bGJld3RycXhPbU8wM1loT0JGd2JDRzFmU1pLU3FSbkRRZ0FPY29INmdhU1RsWXFqXzdLTjNCbU5ES3pIQXZLbTVmMWVhc0FqVlljeWNPOHZMeFlXV2F5Q21ac0lSZVhIOHlnS05sdkR5ZjhJTU9HazJ6MWJR",
}
```

ğŸ‘‰ å®Œå…¨ãªå‡ºåŠ›ä¾‹ã¯ã€[free_scraper/data/](https://github.com/bright-jp/Google-News-Scraper/tree/main/free_scraper/data) ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ç¢ºèªã§ãã¾ã™ã€‚

## Common Scraping Challenges
Google News ã‹ã‚‰ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¯ã‹ãªã‚Šé›£ã—ã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ã‚ˆãã‚ã‚‹å•é¡Œã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™:
1. **CAPTCHA ã¨ã‚¢ãƒ³ãƒãƒœãƒƒãƒˆã®ä»•çµ„ã¿:** Google ã¯ãƒœãƒƒãƒˆãŒã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã®ã‚’é˜²ããŸã‚ã€CAPTCHA ã‚„ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ä»•çµ„ã¿ã‚’é »ç¹ã«æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚
2. **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£:** å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚„é«˜é »åº¦ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã¯ã€ç„¡æ–™ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã§ã¯è² è·ãŒå¤§ãã™ãã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
3. **ã‚°ãƒ­ãƒ¼ãƒãƒ«ãŠã‚ˆã³ãƒ­ãƒ¼ã‚«ãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹:** åœ°åŸŸã‚„è¨€èªãŒç•°ãªã‚‹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹ã«ã¯ã€å¤šãã®å ´åˆã‹ãªã‚Šã®åŠ´åŠ›ã¨æ‰‹å‹•èª¿æ•´ãŒå¿…è¦ã§ã™ã€‚

## Method 2: Bright Data Google News API
ã‚ˆã‚Šå …ç‰¢ãªä»•çµ„ã¿ãŒå¿…è¦ã§ã™ã‹ï¼Ÿ [Bright Data ã® Google News API](https://brightdata.jp/products/serp-api/google-search/news) ã«ã¤ã„ã¦ã”ç´¹ä»‹ã—ã¾ã™ã€‚æ¤œè¨ã™ã‚‹ä¾¡å€¤ãŒã‚ã‚‹ç†ç”±ã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™:

### Key Benefits
- **ã‚¤ãƒ³ãƒ•ãƒ©ã®æ‚©ã¿ã¯ã‚¼ãƒ­:** ãƒ—ãƒ­ã‚­ã‚·ã‚„ CAPTCHA ã®ã“ã¨ã¯å¿˜ã‚Œã¦ãã ã•ã„
- **ã‚¹ã‚±ãƒ¼ãƒ«å‰æ:** é«˜ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§å‡¦ç†ã—ã¾ã™
- **ã‚°ãƒ­ãƒ¼ãƒãƒ«å¯¾å¿œ:** ã©ã®å›½ãƒ»ã©ã®è¨€èªã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚‚å–å¾—ã§ãã¾ã™
- **ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼å„ªå…ˆ:** GDPR ãŠã‚ˆã³ CCPA ã«æº–æ‹ 
- **æˆåŠŸèª²é‡‘:** æˆåŠŸã—ãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã—ã¦ã®ã¿èª²é‡‘ã•ã‚Œã¾ã™
- **è³¼å…¥å‰ã«è©¦ã›ã¾ã™:** ãƒ†ã‚¹ãƒˆç”¨ã« API ã‚’ 20 å›ç„¡æ–™ã§å‘¼ã³å‡ºã›ã¾ã™

## Getting Started with the Google News API
> Google News API ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã«é–¢ã™ã‚‹è©³ç´°ã‚¬ã‚¤ãƒ‰ã¯ã€[Step-by-Step Setup Guide](https://github.com/bright-jp/Google-News-Scraper/blob/main/google_news_api_setup.md) ã‚’ã”è¦§ãã ã•ã„ã€‚
### Key Input Parameters
| **Parameter**| **Required?** | **Description**                                            | **Example**               |
|---------------|--------------|------------------------------------------------------------|---------------------------|
| `url`         | Yes          | ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ Google News URL                                   | `news.google.com`|
| `keyword`     | Yes          | æ¤œç´¢ãƒˆãƒ”ãƒƒã‚¯                        | `"ChatGPT"`             |
| `country`     | No           | ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å–å¾—å…ƒã®å›½                                | `"US"`                    |
| `language`    | No           | å¸Œæœ›ã™ã‚‹è¨€èª                                | `"en"`                    |

### Sample Result
API ã¯æ¬¡ã®ã‚ˆã†ãªçµæœã‚’è¿”ã—ã¾ã™:
```json
{
    "url": "https://www.tomsguide.com/news/live/12-days-of-openai-live-blog-chatgpt-sora",
    "title": "12 Days of OpenAI Day 2 LIVE: o1 full is here and every new ChatGPT AI announcement as it happens",
    "publisher": "Tom's Guide",
    "date": "2024-12-06T20:54:01.000Z",
    "category": null,
    "keyword": "chatgpt",
    "country": "US",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNW9SbTFVTWtkNGFGSjJSVGhGVFJDb0FSaXNBaWdCTWdhQmtJcWpOQWM=-w200-h112-p-df-rw",
    "timestamp": "2024-12-08T10:06:05.122Z",
    "input": {
        "url": "https://news.google.com/",
        "keyword": "chatgpt",
        "country": "US",
        "language": "en",
    },
}
```
ğŸ‘‰ å®Œå…¨ãªå‡ºåŠ›ä¾‹ã¯ã€[news_scraper_output.json](https://github.com/bright-jp/Google-News-Scraper/blob/main/google-news-api-scraper/data/news_scraper_output.json) ãƒ•ã‚¡ã‚¤ãƒ«ã§ç¢ºèªã§ãã¾ã™ã€‚

### Ready-to-Use Python Code
é–‹å§‹ç”¨ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã“ã¡ã‚‰ã§ã™:
```python
import requests
import json
import time


class BrightDataNews:
    def __init__(self, api_token):
        self.api_token = api_token
        self.headers = {
            "Authorization": f"Bearer {api_token}",
            "Content-Type": "application/json",
        }
        self.dataset_id = "gd_lnsxoxzi1omrwnka5r"

    def collect_news(self, search_queries):
        """
        Collect Google News articles using BrightData API
        """
        # 1. Trigger data collection
        print("Starting news collection...")
        trigger_response = self._trigger_collection(search_queries)
        snapshot_id = trigger_response.get("snapshot_id")
        print(f"Snapshot ID: {snapshot_id}")

        # 2. Wait for data to be ready
        print("Waiting for data...")
        while True:
            status = self._check_status(snapshot_id)
            print(f"Status: {status}")

            if status == "ready":
                # Check if data is actually available
                data = self._get_data(snapshot_id)
                if data and len(data) > 0:
                    break
            time.sleep(10)  # Wait 10 seconds before next check
        # 3. Get and save the data
        print("Saving data...")
        filename = f"news_scraper_output.json"
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        print(f"âœ“ Data saved to {filename}")
        print(f"âœ“ Collected {len(data)} news articles")
        return data

    def _trigger_collection(self, search_queries):
        """Trigger news data collection"""
        response = requests.post(
            "https://api.brightdata.com/datasets/v3/trigger",
            headers=self.headers,
            params={"dataset_id": self.dataset_id, "include_errors": "true"},
            json=search_queries,
        )
        return response.json()

    def _check_status(self, snapshot_id):
        """Check collection status"""
        response = requests.get(
            f"https://api.brightdata.com/datasets/v3/progress/{snapshot_id}",
            headers=self.headers,
        )
        return response.json().get("status")

    def _get_data(self, snapshot_id):
        """Get collected data"""
        response = requests.get(
            f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}",
            headers=self.headers,
            params={"format": "json"},
        )
        return response.json()
```
ä½¿ç”¨æ–¹æ³•ã¯ã“ã¡ã‚‰ã§ã™:
```python
# Initialize the client
news_client = BrightDataNews("<YOUR_API_TOKEN>")

# Define what you want to collect
queries = [
    {
        "url": "https://news.google.com/",
        "keyword": "artificial intelligence startups",
        "country": "US",
        "language": "en",
    },
    {
        "url": "https://news.google.com/",
        "keyword": "tech industry layoffs",
        "country": "US",
        "language": "en",
    },
]

# Start collection
try:
    news_data = news_client.collect_news(queries)
    print(f"Successfully collected {len(news_data)} articles")
except Exception as e:
    print(f"Collection failed: {str(e)}")
```
### Understanding the API Implementation
1. **API ãƒˆãƒ¼ã‚¯ãƒ³ã®è¨­å®š**
    - ã¾ãšæœ€åˆã«ã€API ãƒˆãƒ¼ã‚¯ãƒ³ãŒå¿…è¦ã§ã™
    - ã¾ã ãŠæŒã¡ã§ãªã„å ´åˆã¯ã€[setup guide](https://github.com/bright-jp/Google-News-Scraper/blob/main/google_news_api_setup.md) ã‚’ã”ç¢ºèªãã ã•ã„
2. **åé›†ã®é–‹å§‹**
    - æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ API ã«æ¸¡ã—ã¾ã™
    - `snapshot_id` ãŒè¿”ã£ã¦ãã¾ã™
3. **é€²æ—ã®ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°**
    - å‡¦ç†ã«ã¯æ•°åˆ†ã‹ã‹ã‚Šã¾ã™
    - ã“ã®ã‚³ãƒ¼ãƒ‰ã§ã¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è‡ªå‹•çš„ã«ç¢ºèªã—ã¾ã™:
      - "running" = ãƒ‡ãƒ¼ã‚¿åé›†ä¸­
      - "ready" = çµæœã‚’å–å¾—ã™ã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã™ï¼
4. **ãƒ‡ãƒ¼ã‚¿ã®å–å¾—**
    - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒ "ready" ã«ãªã£ãŸã‚‰ã€çµæœã‚’å–å¾—ã—ã¦ä¿å­˜ã—ã¾ã™
    - ãƒ‡ãƒ¼ã‚¿ã¯æ•´ã£ãŸ JSON å½¢å¼ã§æä¾›ã•ã‚Œã¾ã™
    - å„è¨˜äº‹ã«ã¯ã€å…ˆã»ã©èª¬æ˜ã—ãŸã™ã¹ã¦ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå«ã¾ã‚Œã¾ã™

## Customizing Your Data Collection
æ¬¡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€çµæœã‚’å¾®èª¿æ•´ã§ãã¾ã™:
| **Parameter**       | **Type**   | **Description**                                            | **Example**                  |
|---------------------|------------|------------------------------------------------------------|------------------------------|
| `limit`             | `integer`  | å…¥åŠ›ã‚ãŸã‚Šã®æœ€å¤§çµæœæ•°                                   | `limit=10`                   |
| `include_errors`    | `boolean`  | ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ç”¨ã«ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—ã—ã¾ã™                     | `include_errors=true`        |
| `notify`            | `url`      | å®Œäº†æ™‚ã«é€šçŸ¥ã‚’å—ã‘å–ã‚‹ãŸã‚ã® Webhook é€šçŸ¥ URL  | `notify=https://notify-me.com/` |
| `format`            | `enum`     | å‡ºåŠ›å½¢å¼ï¼ˆä¾‹: JSON, NDJSON, JSONL, CSVï¼‰         | `format=json`                |

ğŸ’¡ **Pro Tip:** ãƒ‡ãƒ¼ã‚¿ã‚’ [external storage](https://docs.brightdata.com/scraping-automation/web-data-apis/web-scraper-api/overview#via-deliver-to-external-storage) ã«é…ä¿¡ã™ã‚‹ã‹ã€[webhook](https://docs.brightdata.com/scraping-automation/web-data-apis/web-scraper-api/overview#via-webhook) ã«é…ä¿¡ã™ã‚‹ã‹ã‚‚é¸æŠã§ãã¾ã™ã€‚

----

ã•ã‚‰ã«è©³ç´°ãŒå¿…è¦ãªå ´åˆã¯ã€[official API docs](https://docs.brightdata.com/scraping-automation/web-data-apis/web-scraper-api/overview) ã‚’ã”ç¢ºèªãã ã•ã„ã€‚